{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66fc372-c1d1-48db-99b8-0df71f7f2476",
   "metadata": {},
   "source": [
    "**Data Agumentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d946070-4cb8-4a26-a61e-1a7e88c2afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d344b61-f612-4347-8d06-951fcc1ff5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f550fe-813b-4284-aa96-20e6c36308ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "from skimage import filters\n",
    "from skimage import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0360f2-bfd1-4b0e-9856-0bfc1ae6ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('test images/letter-1.png',target_size=(600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55238088-152c-4d40-94a4-08b6f09b0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f82de26-020f-4b72-b366-02aa78ad314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    fill_mode= 'reflect'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bb96e-3337-4b50-98d7-e21f9e37c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6781f2-0225-48ac-85eb-0f27ac373e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c62ad17-0547-4bdf-bc93-b87753ec8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91105879-ac41-42ed-8945-81e7ad21b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'test images/'\n",
    "size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2463fe2-c799-405e-ade4-6f2d15bc8b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\PIL\\TiffImagePlugin.py:845: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "my_images = os.listdir(image_dir)\n",
    "for i, image_name in enumerate(my_images):\n",
    "    if (image_name.split('.')[1]=='jpg') or (image_name.split('.')[1]=='png'):\n",
    "        image = io.imread(image_dir+image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((size,size))\n",
    "        dataset.append(np.array(image))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "882886fe-7bc0-480b-96d6-e7bd8bf034ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(dataset)\n",
    "x_train_copy = x.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d3f2f-6641-4663-af51-867befbb22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_batch = img.reshape(1,600,600,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8db5ef67-ed6b-46d7-b4b2-cb743cbb3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for output in datagen.flow(x_train_copy,batch_size=16,save_to_dir='augmented_img',save_prefix='aug',save_format='jpg'):\n",
    "    augmented_img = output[0].astype(np.uint8)\n",
    "    # **Verify and Reshape if Necessary**\n",
    "    if augmented_img.shape != (128, 128, 3):\n",
    "        resized_img = cv2.resize(augmented_img, (img_width, img_height))  # Reshape if needed\n",
    "        augmented_img = resized_img.copy()  # Update the augmented image\n",
    "      \n",
    "    # compressed_img = cv2.imencode('.jpg', augmented_img, [cv2.IMWRITE_JPEG_QUALITY, 50])[1]\n",
    "    # degraded_img = cv2.imdecode(compressed_img, cv2.IMREAD_COLOR)\n",
    "    # output = random_noise(degraded_img, mode='gaussian', var=0.01)\n",
    "    # blurred_img = filters.gaussian(output, sigma=1)\n",
    "    i=i+1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42363c49-e23b-4991-bd0e-278c973f0409",
   "metadata": {},
   "source": [
    "**Split Data into training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dee9c816-51bd-42b1-96c2-b02ec5f54b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eae9856a-a5d8-400d-bda1-9b5a761e77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'augmented_img'\n",
    "\n",
    "# Define image dimensions\n",
    "img_width, img_height = 128, 128  # Example dimensions, adjust as needed\n",
    "\n",
    "# Load and preprocess images\n",
    "images = []\n",
    "for img_name in os.listdir(data_dir):\n",
    "    img = load_img(os.path.join(data_dir, img_name), target_size=(128, 128))\n",
    "    img_array = img_to_array(img)\n",
    "    images.append(img_array)\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28ad35da-c755-4d60-bb26-57540011834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (92, 128, 128, 3)\n",
      "Test set shape: (23, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "x_train, x_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of training and test sets\n",
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Test set shape:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e61a1-ef17-4455-a2fd-d3a5b652ffe2",
   "metadata": {},
   "source": [
    "**Add Autoencoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb5b74f9-07d2-40f5-be11-d1276b4a6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3b980a8-703b-4060-83a8-7b123121adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9854a14d-1c06-443d-b472-dabb03622d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)  # Output has 3 channels for RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e87e4156-f4f1-42ed-987e-dd8abf113871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')  # Using Mean Squared Error loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82c6739c-913e-4af1-b5e0-37cdd4bb29f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected input shape for the autoencoder model: (None, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected input shape for the autoencoder model:\", autoencoder.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80dd36d2-6aef-4226-8c1b-3d6ee1e03aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 64, 64, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 64, 64, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 32, 32, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 32, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 16, 16, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 8)         584       \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSamplin  (None, 32, 32, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 32, 32, 8)         584       \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSampli  (None, 64, 64, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 62, 62, 16)        1168      \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSampli  (None, 124, 124, 16)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 124, 124, 3)       435       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4963 (19.39 KB)\n",
      "Trainable params: 4963 (19.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b8b9eb9-4077-467f-9576-0a1323d47ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 124 and 128 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model/conv2d_6/Sigmoid, IteratorGetNext:1)' with input shapes: [?,124,124,3], [?,128,128,3].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the autoencoder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenhchrxlf.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 124 and 128 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model/conv2d_6/Sigmoid, IteratorGetNext:1)' with input shapes: [?,124,124,3], [?,128,128,3].\n"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a5a9d-d955-4760-b9dd-08fd1e7a8251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
