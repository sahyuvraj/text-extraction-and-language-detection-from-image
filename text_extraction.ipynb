{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000690de-e0d8-4feb-a15a-bab8d064f8d6",
   "metadata": {},
   "source": [
    "**installation of required libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b214d-b122-4481-a55e-0f2d95ee79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c47ed4-02b1-431f-9381-4d8d35e98164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b430e5-b1c3-4d25-b91a-12647fd8a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6dcf58-122a-44f3-b010-ea6c10d2d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775d0a9-4c24-4caa-8ed6-41c20fb4d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303d93d-2bfe-41db-bc57-fd6de5d0539a",
   "metadata": {},
   "source": [
    "**IMPORT libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3811d6b6-5e34-4260-81ac-9e9a4fb38d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import pytesseract\n",
    "    import cv2\n",
    "    from matplotlib import pyplot as plt\n",
    "    from PIL import Image\n",
    "    import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e06da-eb75-4afe-a25c-3f3a19b8a85d",
   "metadata": {},
   "source": [
    "**SHOW IMAGES FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee8c599-3b55-4a56-a67d-36a47259b762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc-text.jpg\n",
      "bound-text-1.jpg\n",
      "bound-text-2.jpg\n",
      "Cn.pdf\n",
      "contact-1.jpg\n",
      "degraded.png\n",
      "degraded2.png\n",
      "extracted text.png\n",
      "hello-text.jpg\n",
      "hindi-news-1.jpg\n",
      "hindi-news-2.jpg\n",
      "hindi-text-1.jpg\n",
      "hindi-text-2.jpg\n",
      "image-paths.txt\n",
      "jap-text-1.png\n",
      "jap-text-2.png\n",
      "letter-1.png\n",
      "magazine-1.jpg\n",
      "news-1.png\n",
      "news-2.jpg\n",
      "portu-text-1.jpg\n",
      "portu-text-2.jpg\n",
      "selfie-circle.jpg\n",
      "sin-text-1.gif\n",
      "sin-text-2.gif\n",
      "span-text-1.png\n",
      "tam-text-1.png\n"
     ]
    }
   ],
   "source": [
    "test_img_path = \"C:/Users/hp/Desktop/jupyter/test images/\"\n",
    "create_path = lambda f : os.path.join(test_img_path, f)\n",
    "test_image_files = os.listdir(test_img_path)\n",
    "for f in test_image_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98c96b-c7a1-4c12-958f-ebba5593011f",
   "metadata": {},
   "source": [
    "**SHOW IMAGE USING PATH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44ba81-46a5-4a38-9f83-b96ce1a6685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb96bba0-a98b-4c9f-9d60-d761fa31edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_path, size=(500, 500)):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, size)\n",
    "    cv2.imshow(\"IMAGE\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "show_image(\"C:/Users/hp/Desktop/jupyter/test images/letter-1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fbd52c-7742-4652-b593-42775666215e",
   "metadata": {},
   "source": [
    "**configure tesseract path in implementations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf047686-47a3-497d-8b37-29b5289d9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa1055-e82f-4173-92de-3ff699eb0d6a",
   "metadata": {},
   "source": [
    "**Checkout available languages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0a9174-833b-4012-8e1a-f47fe0956482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n",
      "hin\n",
      "osd\n"
     ]
    }
   ],
   "source": [
    "# using cmd : tesseract --list-lang\n",
    "avb_langs = pytesseract.get_languages(config='')\n",
    "for lang in avb_langs:\n",
    "    print(lang)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ce731-4ebe-4bb3-b5ee-d5f5eb548fd4",
   "metadata": {},
   "source": [
    "**EXTARCT TEXT FROM IMAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f920d6e5-d87d-4ef5-a7b4-688cf87a727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAR SS ALE\n",
      "\n",
      "without regret\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_text(img_no):\n",
    "    image_path = test_image_files[img_no]\n",
    "    path = create_path(image_path)\n",
    "\n",
    "    image = Image.open(path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    print(text)\n",
    "    show_image(path)\n",
    "    return text\n",
    "    \n",
    "    \n",
    "text = extract_text(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2c6348-acbf-43f4-a72d-3790636c324b",
   "metadata": {},
   "source": [
    "**Hindi Language Text Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa8be68-4c79-4e06-9cd8-24d749d09a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "सुखद : आसन वेटलैंड में पलास\n",
      "फिंश ईगल की नेसिंटग शुरू\n",
      "\n",
      "जागरण संवाददाता, विकासनगर :देश के पहले\n",
      "कंजरवेशन रिजर्व आसन वेटलैंड में प्रवास पर आए\n",
      "पलास फिश ईगल (वैज्ञानिक नाम हालियाइटस\n",
      "ल्यूकॉरीपस ) के जोड़े ने सेमल के पेड़ पर\n",
      "आशियाना तैयार करना शुरू कर दिया है । चकराता\n",
      "वन प्रभाग इसे एक सुखद संकेत मान रहा है। वहीं\n",
      "आसन नमथभूमि में प्रवासी परिंदों की संख्या बढ़कर\n",
      "पांच हजार के करीब हो गई है ।शिकारियों पर अंकुश\n",
      "को सशस्त्र वन टीम की रात दिन गश्त चल रही है।\n",
      "रविवार को जीएमवीएन के आसन पर्यटन स्थल पर\n",
      "आए पक्षी प्रेमियों व पर्यटकों ने बोटिंग के साथ ही बर्ड\n",
      "वाचिंग का भी आनंद लिया।\n",
      "\n",
      "दुर्लभ प्रजाति के पलाश फिश ईगल मुख्य रूप से\n",
      "कजाकिस्तान, मंगोलिया, बंग्लादेश आदि देशों से\n",
      "प्रवास पर आते हैं पिछले 50 साल से पलास फिश\n",
      "ईगल का जोड़ा प्रवास पर आ स्हा है। इस बार जोड़े ने\n",
      "नमभुूमि क्षेत्र के आरक्षित वन क्षेत्र में सेमल के पेड़\n",
      "पर आशियाना तैयार करना शुरू कर दिया है । आसन\n",
      "रेंजर जवाहर सिंह तोमर व वन बीट अधिकारी प्रदीप\n",
      "सक्सेना ने लंबे समय बाद आशियाना तैयार कर रहे\n",
      "पलाश फिश ईगल की गतिविधियों पर ध्यान देना\n",
      "शुरू कर दिया है। प्रभाग अधिकारी इसे सुखद मान\n",
      "रहे हैं। वहीं 20 प्रजातियों के प्रवासी परिंदों की संख्या\n",
      "बढ़कर पांच हजार के करीब पहुंच गई है।\n",
      "अधिकारियों ने बताया कि जल्द ही पक्षी विशेषज्ञ\n",
      "गणना के लिए नमभूमि आएंगे। जिसके बाद पक्षियों\n",
      "से संबंधित आंकड़े जारी किए जाएंगे ।\n",
      "\n",
      "बीते कुछ समय से लगातार सूखी ठंड पड़ने से भी\n",
      "प्रवासी पक्षियों की आमद में कमी आ गई थी, जो\n",
      "पिछले वर्ष की अपेक्षा काफी कम थी। इसे लेकर\n",
      "पक्षी विशेषज्ञ चिंता जता रहे थे। लेकिन, धीरे-धीरे\n",
      "बढ़ रही पक्षियों की संख्या से विशेषज्ञों व वन कर्मियों\n",
      "ने राहत की सांस ली है ।चकराता वन प्रभाग के रेंजर\n",
      "आसन जवाहर सिंह तोमर व वन बीट अधिकारी\n",
      "प्रदीप सक्सेना के अनुसार डीएफ-ओ दीपचंद आर्य\n",
      "\n",
      "रह\n",
      "\n",
      "आसनवेटलैंड में सेमल के पेड पर बैठा पलाश फिश\n",
      "'ईगल ० जागरण\n",
      "\n",
      "बोटिंग के साथ बर्ड वाचिंग\n",
      "\n",
      "डिनर जैसे. 5\n",
      "\n",
      "जीएमवीएन के आसन पर्यटन स्थल पर नववर्ष\n",
      "के पहले दिन भारी संख्या में पर्यटक व पक्षी प्रेमी\n",
      "उमड़े । जिन्होंने पैडल बोट का आनंद लेने के साथ\n",
      "ही बर्ड वाचिंग भी की । आसन पर्यटन स्थल के\n",
      "प्रबंचक अजयपाल कंडारी के अनुसार बोट की\n",
      "रक्त संख्या बढ़ाने के प्रयास किए\n",
      "जारहे हैं ।\n",
      "\n",
      "के निर्देश के चलते प्रवासी परिंदों की सुरक्षा को गश्त\n",
      "पर विशेष ध्यान दिया जा रहा है । प्रवासी परिंदों की\n",
      "संख्या में इजाफा हो रहा है, जो आने वाले समय के\n",
      "लिए सुस्वद संकेत है ।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def hindi_text(image_name):\n",
    "    path = create_path(image_name)\n",
    "    image = Image.open(path)\n",
    "    text = pytesseract.image_to_string(image, lang='hin')\n",
    "    print(text)\n",
    "    show_image(path)\n",
    "    return text\n",
    "\n",
    "hindi_txt = hindi_text(\"hindi-news-2.jpg\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c744243-d95e-43d7-9605-26bfd2fea24e",
   "metadata": {},
   "source": [
    "**Language Identification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf795b-cb0d-40be-bb4c-bbb72c3338b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71815abb-89ed-4f61-acca-39f35b72abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a97f9e-48fb-40d2-b23c-799f2b3963ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Language Detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c12fec7-c0bb-4c8c-b40a-0712cf279035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd2c7b-f08e-4ec0-921c-c4b8ad780862",
   "metadata": {},
   "source": [
    "**Remove punctuation from the text and convert text into lower case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd05e7f-5c34-41af-891e-f50f2dcd53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(text):\n",
    "    for pun in string.punctuation:\n",
    "        text = text.replace(pun,\"\")\n",
    "    text = text.lower()\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcba3e5-c233-480f-b72c-716d07e771d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(remove_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5552d7e-99eb-4681-b3d4-c1d1a23eb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99eb1b-9421-4318-bd78-48873dd9175b",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3b001-943a-48f0-aaa6-3341cb9c554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d0a6f5-1c6e-4e51-96ed-48580ab03d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0]\n",
    "Y = df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "996bf167-b082-4928-b6d8-912d5d54c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b0026e4-3764-4a7e-865b-578d1c4beeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94946d0-622f-4563-8978-7381d1b1e013",
   "metadata": {},
   "source": [
    "**Feature Extraction or Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f6605bc-d8a3-4813-9e40-2123f2737259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "587a0bf1-998b-4c60-8d44-98cbba9d7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = feature_extraction.text.TfidfVectorizer(ngram_range=(1,2),analyzer = 'char')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71189d1f-5d03-4d38-9ca6-f4a7f2bd2cfa",
   "metadata": {},
   "source": [
    "**Pipelining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c2f4f3-f39b-4112-82e8-58ffabe5b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c402f769-bf24-424e-b596-734ae793d95f",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04a4804b-fc6d-45d3-a153-6b6669cf3975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_pipe = pipeline.Pipeline([('vec',vec),('clf',linear_model.LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d6c42-0014-4834-901b-d7fcd39c9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c85755-dc56-4798-bda0-b6f5db354101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0552d78-10a3-42a2-9774-c6ef4693c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5bf1d96-00d6-47c7-9ec8-04e0c65b8bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sweedish', 'English', 'Tamil', ..., 'Portugeese', 'Malayalam',\n",
       "       'Russian'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82639966-ec64-43b9-82d6-53c76e2c0dc1",
   "metadata": {},
   "source": [
    "Accuracy, Precision_score, Recall_score, F1_score in Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2216c32c-5a61-4b04-8b79-4d4f46ce13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "Accuracy = metrics.accuracy_score(y_test,y_predict)*100\n",
    "precision_score = metrics.precision_score(y_test,y_predict,average='weighted')*100\n",
    "recall_score = metrics.recall_score(y_test,y_predict,average='weighted')*100\n",
    "f1_score = metrics.f1_score(y_test,y_predict,average='weighted')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37e9a68d-43aa-49c0-a704-286877147374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.43713733075435"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "467a45e8-bc6a-4c18-ac9c-d4f211173da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.44102516527536"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32b9bc89-485c-4446-b693-7cb67b89d7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.43713733075435"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3be9191-2e2e-45d5-a634-a3136bc85598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.43165711420558"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05276b-8737-441f-aae0-4828716b1a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8203d5-1640-4158-a914-0246a4477a45",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae32b06c-e3bc-4ca8-999e-3a0498a15b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe1 = pipeline.Pipeline([('vec',vec),('clf',MultinomialNB())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe3812-9f9a-49c9-b956-434ae193ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "599cfc07-a23d-4b2c-b34e-58608ace5ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0844216-ec03-4ccf-979f-0e44ce3d449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict1 = model_pipe1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db395354-6007-4223-8590-2883e872a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df61436-5eb4-42e0-be6c-71e2144e702b",
   "metadata": {},
   "source": [
    "Accuracy, Precision_score, Recall_score, F1_score in Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05e131-3763-4926-955c-29c60cbe7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1fd2590-2b9e-4127-85fa-c22c05c58820",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy1 = metrics.accuracy_score(y_test,y_predict1)*100\n",
    "precision_score1 = metrics.precision_score(y_test,y_predict1,average='weighted')*100\n",
    "recall_score1 = metrics.recall_score(y_test,y_predict1,average='weighted')*100\n",
    "f1_score1 = metrics.f1_score(y_test,y_predict1,average='weighted')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fc71366-1391-45e2-8798-f389c59b37ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.1779497098646"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5ea52b8-5266-4000-810c-0fbae3ea4868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.88657342693602"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b0eab34-3466-40c8-a564-54c4ed6afd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.1779497098646"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f661201-d238-49dc-a63e-0c5d9eb94c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.90670844068445"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1231f-adf6-4fa3-aac0-36ff24e5eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_predict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d726ea-15e3-4c3f-9311-1b23a50a84ee",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34cb053c-a2b0-4417-9ce9-2e5187d7a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe2 = pipeline.Pipeline([('vec',vec),('clf',SVC())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72787e21-5072-4920-bf11-7009134e10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08316e7c-5d1b-4dec-ae73-6a3e75b561f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', SVC())])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e5be8b5-7380-426c-9274-d1993d3f07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict2 = model_pipe2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899e044-0179-49e5-ad3d-af745c3667cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b361d25a-748b-48b4-9a04-d3ead18bd26c",
   "metadata": {},
   "source": [
    "Accuracy, Precision_score, Recall_score, F1_score in Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00191950-c559-4d84-a48c-7644ce0302fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy2 = metrics.accuracy_score(y_test,y_predict2)*100\n",
    "precision_score2 = metrics.precision_score(y_test,y_predict2,average='weighted')*100\n",
    "recall_score2 = metrics.recall_score(y_test,y_predict2,average='weighted')*100\n",
    "f1_score2 = metrics.f1_score(y_test,y_predict2,average='weighted')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a782c5de-1d7b-43ca-917c-53c7df149e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.21083172147002"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35638e98-429c-42f2-a95a-bd0f63b04f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.216509627159"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f59105ee-d56c-4aff-be6c-e109563ccfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.21083172147002"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d942d2d-89dc-425e-aedc-173ec321840e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.20813760523309"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002bc49-c8f4-49db-9b68-af8f783ef4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_predict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da732409-5563-4649-bc08-0e2ac576af38",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9453480e-7290-433c-a388-1c7b058817e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62b1b2b7-550c-4aba-89ef-b0a0a655454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe3 = pipeline.Pipeline([('vec',vec),('clf',DecisionTreeClassifier(random_state=42))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37869f95-6e9a-4e73-8451-c0ab30409f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, DecisionTreeClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, DecisionTreeClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05fb7233-a644-4e2a-aad8-26cde46414f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict3 = model_pipe3.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bb2a45-0e2a-448f-98fa-b333f0feb203",
   "metadata": {},
   "source": [
    "Accuracy, Precision_score, Recall_score, F1_score in Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98425422-a12d-4c08-bf53-1e46c2b02508",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy3 = metrics.accuracy_score(y_test,y_predict3)*100\n",
    "precision_score3 = metrics.precision_score(y_test,y_predict3,average='weighted')*100\n",
    "recall_score3 = metrics.recall_score(y_test,y_predict3,average='weighted')*100\n",
    "f1_score3 = metrics.f1_score(y_test,y_predict3,average='weighted')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "289167fc-53fb-422d-b8aa-a18adc604f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.16827852998065"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c6e88ee-aba9-46bb-b31f-8c0d6d7ca5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.29158178235646"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "520a464c-00ec-4a06-a704-4280e6c06980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.16827852998065"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f098a6a8-70af-4866-8cec-2ab4edd63e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.19977667335702"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ea034-bc1a-4c30-9b36-84ddfaa8039c",
   "metadata": {},
   "source": [
    "**K-NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20d4a10a-d9ef-4f25-adb4-179f250c7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93ffb6a5-b7ae-4d32-aadf-aca328cb8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe4 = pipeline.Pipeline([('vec',vec),('clf',KNeighborsClassifier(n_neighbors=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4110553e-2e65-42f6-8e6e-48498189fe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, KNeighborsClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='char', ngram_range=(1, 2))),\n",
       "                ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5fdb9232-72c2-4f76-85f5-757c2d69e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict4 = model_pipe4.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de601ee1-e558-4ef4-8a8f-b65cd38d31ae",
   "metadata": {},
   "source": [
    "Accuracy, Precision_score, Recall_score, F1_score in Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59ad0a5e-c746-4406-9803-aefb13df03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy4 = metrics.accuracy_score(y_test,y_predict4)*100\n",
    "precision_score4 = metrics.precision_score(y_test,y_predict4,average='weighted')*100\n",
    "recall_score4 = metrics.recall_score(y_test,y_predict4,average='weighted')*100\n",
    "f1_score4 = metrics.f1_score(y_test,y_predict4,average='weighted')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9e21cdf-12f4-4ddf-b08a-19fe3de62f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.5183752417795"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c6e93b3-28b4-4387-82fb-0b95bbbd213a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.58989017812375"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9acce27-5df3-40fe-944e-bb4f4c165fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.5183752417795"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57146d6d-087c-4792-a37d-d8a4d3368306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.52218445287123"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79acd69b-fd30-455d-ba15-8f0e12e93335",
   "metadata": {},
   "source": [
    "**Language Prediction Of Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bafcde65-73ff-4180-8aba-2af84c863a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = model_pipe.predict(['''It's been a long time since we saw each\n",
    "other. Do you remember when we met\n",
    "in September, 2020 in Toronto?'''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ad8cfa9-7924-449d-83f8-0ac2b85e1948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8fe8a-1b53-4f27-bea5-cc348877d2bd",
   "metadata": {},
   "source": [
    "**Model Of Language Identification Of The Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788cb607-7e1d-4998-aa59-400620716c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_identification(df,text):\n",
    "    X = df.iloc[:,0]\n",
    "    Y = df.iloc[:,1]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = .2)\n",
    "    vec = feature_extraction.text.TfidfVectorizer(ngram_range=(1,2),analyzer = 'char')\n",
    "    model_pipe = pipeline.Pipeline([('vec',vec),('clf',linear_model.LogisticRegression())])\n",
    "    model_pipe.fit(x_train,y_train)\n",
    "    y_predict = model_pipe.predict([text])\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19ea01-a73c-47f6-b2bb-c0c4293df503",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = language_identification(df,text)\n",
    "language[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d772c29-56c4-4df7-a4d9-2deb7fe88edf",
   "metadata": {},
   "source": [
    "**Restore Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6224249c-266e-4df0-b807-2c14a3f7137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab490f-bec4-4a3e-8c23-7c79828a26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_img(img_path):\n",
    "    img = cv2.imread(img_path)   # Load the degraded image\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (560, 900))\n",
    "    adaptive_result = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 41, 5)\n",
    "    cv2.imshow(\"original_IMAGE\", img)\n",
    "    cv2.imshow(\"adaptive_result\", adaptive_result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return adaptive_result\n",
    "    \n",
    "restored_img = restore_img(\"C:/Users/hp/Desktop/jupyter/test images/letter-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30594bdf-211e-4f84-8ae1-034fd57e5d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     - -------------------------------------- 30.7/981.5 kB ? eta -:--:--\n",
      "     - -------------------------------------- 30.7/981.5 kB ? eta -:--:--\n",
      "     - ----------------------------------- 41.0/981.5 kB 330.3 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 61.4/981.5 kB 409.6 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 71.7/981.5 kB 357.2 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 71.7/981.5 kB 357.2 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 71.7/981.5 kB 357.2 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 71.7/981.5 kB 357.2 kB/s eta 0:00:03\n",
      "     -- ---------------------------------- 71.7/981.5 kB 357.2 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ----- ------------------------------ 143.4/981.5 kB 327.9 kB/s eta 0:00:03\n",
      "     ------- ---------------------------- 204.8/981.5 kB 235.0 kB/s eta 0:00:04\n",
      "     ------- ---------------------------- 204.8/981.5 kB 235.0 kB/s eta 0:00:04\n",
      "     ------- ---------------------------- 204.8/981.5 kB 235.0 kB/s eta 0:00:04\n",
      "     -------- --------------------------- 225.3/981.5 kB 222.1 kB/s eta 0:00:04\n",
      "     -------- --------------------------- 235.5/981.5 kB 218.5 kB/s eta 0:00:04\n",
      "     -------- --------------------------- 235.5/981.5 kB 218.5 kB/s eta 0:00:04\n",
      "     --------- -------------------------- 256.0/981.5 kB 224.8 kB/s eta 0:00:04\n",
      "     --------- -------------------------- 256.0/981.5 kB 224.8 kB/s eta 0:00:04\n",
      "     ---------- ------------------------- 276.5/981.5 kB 227.2 kB/s eta 0:00:04\n",
      "     ---------- ------------------------- 286.7/981.5 kB 224.1 kB/s eta 0:00:04\n",
      "     ----------- ------------------------ 307.2/981.5 kB 234.8 kB/s eta 0:00:03\n",
      "     ----------- ------------------------ 317.4/981.5 kB 228.7 kB/s eta 0:00:03\n",
      "     ------------ ----------------------- 337.9/981.5 kB 235.7 kB/s eta 0:00:03\n",
      "     ------------ ----------------------- 337.9/981.5 kB 235.7 kB/s eta 0:00:03\n",
      "     ------------ ----------------------- 337.9/981.5 kB 235.7 kB/s eta 0:00:03\n",
      "     ------------- ---------------------- 358.4/981.5 kB 232.1 kB/s eta 0:00:03\n",
      "     ------------- ---------------------- 368.6/981.5 kB 229.4 kB/s eta 0:00:03\n",
      "     -------------- --------------------- 389.1/981.5 kB 235.5 kB/s eta 0:00:03\n",
      "     -------------- --------------------- 399.4/981.5 kB 237.3 kB/s eta 0:00:03\n",
      "     --------------- -------------------- 419.8/981.5 kB 240.5 kB/s eta 0:00:03\n",
      "     --------------- -------------------- 419.8/981.5 kB 240.5 kB/s eta 0:00:03\n",
      "     ---------------- ------------------- 440.3/981.5 kB 241.5 kB/s eta 0:00:03\n",
      "     ---------------- ------------------- 450.6/981.5 kB 240.9 kB/s eta 0:00:03\n",
      "     ---------------- ------------------- 450.6/981.5 kB 240.9 kB/s eta 0:00:03\n",
      "     ---------------- ------------------- 450.6/981.5 kB 240.9 kB/s eta 0:00:03\n",
      "     ----------------- ------------------ 471.0/981.5 kB 230.4 kB/s eta 0:00:03\n",
      "     ----------------- ------------------ 481.3/981.5 kB 231.9 kB/s eta 0:00:03\n",
      "     ------------------ ----------------- 501.8/981.5 kB 236.5 kB/s eta 0:00:03\n",
      "     ------------------ ----------------- 501.8/981.5 kB 236.5 kB/s eta 0:00:03\n",
      "     ------------------- ---------------- 522.2/981.5 kB 235.7 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 532.5/981.5 kB 233.8 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 532.5/981.5 kB 233.8 kB/s eta 0:00:02\n",
      "     ------------------- ---------------- 532.5/981.5 kB 233.8 kB/s eta 0:00:02\n",
      "     -------------------- --------------- 553.0/981.5 kB 231.6 kB/s eta 0:00:02\n",
      "     -------------------- --------------- 553.0/981.5 kB 231.6 kB/s eta 0:00:02\n",
      "     -------------------- --------------- 553.0/981.5 kB 231.6 kB/s eta 0:00:02\n",
      "     -------------------- --------------- 563.2/981.5 kB 222.6 kB/s eta 0:00:02\n",
      "     --------------------- -------------- 583.7/981.5 kB 225.1 kB/s eta 0:00:02\n",
      "     --------------------- -------------- 583.7/981.5 kB 225.1 kB/s eta 0:00:02\n",
      "     --------------------- -------------- 583.7/981.5 kB 225.1 kB/s eta 0:00:02\n",
      "     --------------------- -------------- 583.7/981.5 kB 225.1 kB/s eta 0:00:02\n",
      "     --------------------- -------------- 583.7/981.5 kB 225.1 kB/s eta 0:00:02\n",
      "     ---------------------- ------------- 604.2/981.5 kB 214.8 kB/s eta 0:00:02\n",
      "     ----------------------- ------------ 634.9/981.5 kB 219.7 kB/s eta 0:00:02\n",
      "     ----------------------- ------------ 645.1/981.5 kB 219.7 kB/s eta 0:00:02\n",
      "     ------------------------ ----------- 665.6/981.5 kB 223.1 kB/s eta 0:00:02\n",
      "     ------------------------ ----------- 665.6/981.5 kB 223.1 kB/s eta 0:00:02\n",
      "     ------------------------ ----------- 665.6/981.5 kB 223.1 kB/s eta 0:00:02\n",
      "     ------------------------- ---------- 686.1/981.5 kB 221.8 kB/s eta 0:00:02\n",
      "     ------------------------- ---------- 686.1/981.5 kB 221.8 kB/s eta 0:00:02\n",
      "     ------------------------- ---------- 696.3/981.5 kB 217.4 kB/s eta 0:00:02\n",
      "     -------------------------- --------- 716.8/981.5 kB 220.6 kB/s eta 0:00:02\n",
      "     -------------------------- --------- 716.8/981.5 kB 220.6 kB/s eta 0:00:02\n",
      "     -------------------------- --------- 716.8/981.5 kB 220.6 kB/s eta 0:00:02\n",
      "     -------------------------- --------- 716.8/981.5 kB 220.6 kB/s eta 0:00:02\n",
      "     -------------------------- --------- 716.8/981.5 kB 220.6 kB/s eta 0:00:02\n",
      "     -------------------------- --------- 727.0/981.5 kB 209.5 kB/s eta 0:00:02\n",
      "     -------------------------- --------- 727.0/981.5 kB 209.5 kB/s eta 0:00:02\n",
      "     --------------------------- -------- 747.5/981.5 kB 209.8 kB/s eta 0:00:02\n",
      "     ---------------------------- ------- 768.0/981.5 kB 211.8 kB/s eta 0:00:02\n",
      "     ---------------------------- ------- 768.0/981.5 kB 211.8 kB/s eta 0:00:02\n",
      "     ---------------------------- ------- 778.2/981.5 kB 210.1 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 778.2/981.5 kB 210.1 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 778.2/981.5 kB 210.1 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 798.7/981.5 kB 207.7 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 798.7/981.5 kB 207.7 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 809.0/981.5 kB 204.5 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 809.0/981.5 kB 204.5 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 809.0/981.5 kB 204.5 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 829.4/981.5 kB 203.2 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 829.4/981.5 kB 203.2 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 829.4/981.5 kB 203.2 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 849.9/981.5 kB 202.0 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 860.2/981.5 kB 187.6 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 880.6/981.5 kB 189.5 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 890.9/981.5 kB 190.4 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 890.9/981.5 kB 190.4 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 911.4/981.5 kB 191.6 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 911.4/981.5 kB 191.6 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 931.8/981.5 kB 190.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 931.8/981.5 kB 190.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 942.1/981.5 kB 189.3 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 942.1/981.5 kB 189.3 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 942.1/981.5 kB 189.3 kB/s eta 0:00:01\n",
      "     -----------------------------------  962.6/981.5 kB 187.5 kB/s eta 0:00:01\n",
      "     -----------------------------------  962.6/981.5 kB 187.5 kB/s eta 0:00:01\n",
      "     -----------------------------------  962.6/981.5 kB 187.5 kB/s eta 0:00:01\n",
      "     -----------------------------------  962.6/981.5 kB 187.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ 981.5/981.5 kB 185.0 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993254 sha256=3001230cafc02932bc2d1d238504f1c0a720ec1f51746d81f9679b0e86b3ffed\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\95\\03\\7d\\59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce2d730-3fae-40f7-8c09-982cfa13cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "def detect_languages(board_text):\n",
    "    language = detect(text)\n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e83c7d1-b69a-454f-ad1f-517c086ec608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    }
   ],
   "source": [
    "la = detect_languages(\" la Place de la cathédrale de Strasbourg est un méli-mélo de maisons anciennes \")\n",
    "print(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb31544-c46b-4dbb-b26d-dd62dc9d8661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
